{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting NBA\n",
    "\n",
    "This is a project for predicting the outcome of NBA games.\n",
    "We will be using different Machine Learning for prediction and comparing the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset: https://www.kaggle.com/nathanlauga/nba-games\n",
    "\n",
    "This dataset contains data of every NBA game played from 2014 season to now. For our training set, we can use seasons\n",
    "2014/2015-2017/2018, where we would test our model on 2018/2019 season. The reason, we will not be using later seasons\n",
    "(for now) is that after those seasons Covid-19 hit. After that, the games were postponed, players were in quarantine,\n",
    "no fans, play-offs were played in the bubble and similar noise in the data from real-life events."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Original post: https://towardsdatascience.com/predicting-the-outcome-of-nba-games-with-machine-learning-a810bb768f20\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from helper_functions import calculate_elo\n",
    "\n",
    "filename = \"Data/games.csv\"\n",
    "data = pd.read_csv(filename, parse_dates=[\"GAME_DATE_EST\"])\n",
    "\n",
    "test_date = datetime.strptime(\"2018-06-09\", \"%Y-%m-%d\")\n",
    "start_date = datetime.strptime(\"2013-06-30\", \"%Y-%m-%d\")\n",
    "\n",
    "train_set = data[(data[\"GAME_DATE_EST\"] < test_date)]\n",
    "train_set = train_set[(train_set[\"GAME_DATE_EST\"] > start_date)]\n",
    "\n",
    "end_date = datetime.strptime(\"2019-06-14\", \"%Y-%m-%d\")\n",
    "\n",
    "test_set = data[(data[\"GAME_DATE_EST\"] < end_date)]\n",
    "test_set = test_set[(test_set[\"GAME_DATE_EST\"] > test_date)]\n",
    "\n",
    "teams_data = pd.read_csv(\"Data/teams.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Establishing baseline\n",
    "First we need to get baseline for the prediction accuracy. First is to randomly pick a winner from two team or\n",
    "next is to predict that home team wins every time. We can try both and pick the best one.\n",
    "\n",
    "\n",
    "### Random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from random import random\n",
    "\n",
    "test_out_random = list()\n",
    "\n",
    "for n,i in test_set.iterrows():\n",
    "    if random() < 0.5:\n",
    "        test_out_random.append(0)\n",
    "    else:\n",
    "        test_out_random.append(1)\n",
    "\n",
    "random_eval = 0;\n",
    "for i in range(0, len(test_out_random)):\n",
    "    if test_out_random[i] == test_set.iloc[i][\"HOME_TEAM_WINS\"]:\n",
    "        random_eval += 1\n",
    "\n",
    "print(\"Accuracy of random winner: \" + str(random_eval * 100 / len(test_out_random)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random winner: 50.72568940493469\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Home team always wins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of home team always wins: 58.78084179970973\n"
     ]
    }
   ],
   "source": [
    "home_team_eval = 0\n",
    "for i in range(0, len(test_set.index)):\n",
    "    if test_set.iloc[i][\"HOME_TEAM_WINS\"] == 1:\n",
    "        home_team_eval += 1\n",
    "\n",
    "print(\"Accuracy of home team always wins: \" + str(home_team_eval * 100 / len(test_set.index)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our baseline for our model's accuracy will be the probability that home team always wins (almost 60%).\n",
    "\n",
    "\n",
    "\n",
    "## ELO Rating\n",
    "\n",
    "Until now, we were only looking at win/lose ratio. ELO rating is improved win/lose stat, due to the fact, it takes into\n",
    "consideration history of previous matches from teams, but not in simple 0/1. It's a score, where every team starts at\n",
    "1500 points, after that every team receives or loses points for win or loss. Increase or deduction in points is dependent\n",
    "on different parameters (location of the match and others). This metric is much better representation of the team's\n",
    "strength, than simple win/lose metric."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ELO rating: 61.10304789550072\n"
     ]
    }
   ],
   "source": [
    "train_set.sort_values(\"GAME_DATE_EST\", inplace=True, ascending=True)\n",
    "test_set.sort_values(\"GAME_DATE_EST\", inplace=True, ascending=True)\n",
    "\n",
    "score_init = [1500 for i in range(0, len(teams_data.index))]\n",
    "teams_data[\"ELO_RATING\"] = score_init\n",
    "\n",
    "for i in range(0, len(train_set.index)):\n",
    "\n",
    "    if i > 0 and train_set.iloc[i][\"SEASON\"] != train_set.iloc[i - 1][\"SEASON\"]:\n",
    "        for j in range(0, len(teams_data.index)):\n",
    "            teams_data.at[j, \"ELO_RATING\"] = teams_data.at[j, \"ELO_RATING\"] * 0.75 + (0.25*1505)\n",
    "\n",
    "    home_id = train_set.iloc[i][\"TEAM_ID_home\"]\n",
    "    away_id = train_set.iloc[i][\"TEAM_ID_away\"]\n",
    "    win_lose = train_set.iloc[i][\"HOME_TEAM_WINS\"]\n",
    "    home_pts = train_set.iloc[i][\"PTS_home\"]\n",
    "    away_pts = train_set.iloc[i][\"PTS_away\"]\n",
    "    home_team_index = teams_data.index[teams_data[\"TEAM_ID\"] == home_id].tolist()[0]\n",
    "    away_team_index = teams_data.index[teams_data[\"TEAM_ID\"] == away_id].tolist()[0]\n",
    "    home_elo = teams_data.iloc[home_team_index][\"ELO_RATING\"]\n",
    "    away_elo = teams_data.iloc[away_team_index][\"ELO_RATING\"]\n",
    "    teams_data.at[home_team_index, \"ELO_RATING\"] = calculate_elo(home_elo, away_elo, win_lose, abs(home_pts-away_pts), 0)\n",
    "    teams_data.at[away_team_index, \"ELO_RATING\"] = calculate_elo(away_elo, home_elo, 1-win_lose, abs(home_pts-away_pts), 1)\n",
    "\n",
    "for j in range(0, len(teams_data.index)):\n",
    "            teams_data.at[j, \"ELO_RATING\"] = teams_data.at[j, \"ELO_RATING\"] * 0.75 + (0.25*1505)\n",
    "\n",
    "prediction_count = 0\n",
    "for i in range(0, len(test_set.index)):\n",
    "    home_id = test_set.iloc[i][\"TEAM_ID_home\"]\n",
    "    away_id = test_set.iloc[i][\"TEAM_ID_away\"]\n",
    "    home_pts = test_set.iloc[i][\"PTS_home\"]\n",
    "    away_pts = test_set.iloc[i][\"PTS_away\"]\n",
    "    home_team_index = teams_data.index[teams_data[\"TEAM_ID\"] == home_id].tolist()[0]\n",
    "    away_team_index = teams_data.index[teams_data[\"TEAM_ID\"] == away_id].tolist()[0]\n",
    "    home_elo = teams_data.iloc[home_team_index][\"ELO_RATING\"]\n",
    "    away_elo = teams_data.iloc[away_team_index][\"ELO_RATING\"]\n",
    "    win_lose = 0\n",
    "    if home_elo >= away_elo:\n",
    "        win_lose = 1\n",
    "    teams_data.at[home_team_index, \"ELO_RATING\"] = calculate_elo(home_elo, away_elo, win_lose, abs(home_pts-away_pts), 0)\n",
    "    teams_data.at[away_team_index, \"ELO_RATING\"] = calculate_elo(away_elo, home_elo, 1-win_lose, abs(home_pts-away_pts), 1)\n",
    "    if win_lose == test_set.iloc[i][\"HOME_TEAM_WINS\"]:\n",
    "        prediction_count += 1\n",
    "\n",
    "print(\"Accuracy of ELO rating: \" + str(prediction_count * 100 / len(test_set.index)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, ELO rating improves the result, and we break the barrier of 60% accuracy. More interesting thing is that we get this result of more than 60% when the predictions are not independent, where an output of one prediction is an input in another through ELO rating. With this in mind, ELO rating is a very good and interesting attribute."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}